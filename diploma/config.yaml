model:
  name: autoencoder_upsampler_res_blocks_2
  path: diploma/models/autoencoder_upsampler_res_blocks_2.pth
  #input_size: 256
  hidden_size: 512
  #output_size: 10
  #upsample_factor: 4

train:
  device: cuda
  epochs: 150
  learning_rate: 0.00005
  batch_size: 32
  optimizer:
    name: Adam
    weight_decay: 0.00001

dataset:
  name: DIV2K
  data_path: diploma/data/DIV2K
  transform:
    - RandomHorizontalFlip
    - RandomCrop:
        size: 256
    - ToTensor



# scheduler:
#   name: StepLR
#   step_size: 10
#   gamma: 0.1

logging:
  log_dir: diploma/log/
  save_dir: /path/to/checkpoints